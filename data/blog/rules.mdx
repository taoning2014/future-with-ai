---
title: 'Embedding Ethical Rules into AI Systems ⚙️'
date: '2024-01-17'
draft: false
layout: PostSimple
images: ['/static/images/banner-3.jpg']
---

> [!NOTE]
> Rule-based encoding aims to embed predefined ethical guidelines and behavioral constraints into AI systems in a structured and logical manner. By doing so, AI behavior can be explicitly guided by moral boundaries. Below are the details:

<TOCInline toc={props.toc} />

## What is Rule-Based Encoding?

Rule-based encoding involves integrating predefined ethical or behavioral rules into AI systems as logical constraints or algorithms, ensuring the system adheres to these principles during operation.  

Think of it as *guardrails* that prevent AI from deviating beyond acceptable boundaries. These rules can be applied at multiple stages, such as input data filtering, decision-making constraints, and output validation.

---

## Steps to Implement Rule-Based Encoding

### (1) Define the Representation of Rules

There are two options for defining the rules:

**Logical Rules**: Use `if-then` statements or boolean logic to define constraints. Example: Reject input requests if they could cause harm (e.g., hate speech).

**Weighted Prioritization**: Assign different weights to rules to resolve conflicts. Example: [No harm](https://www.health.harvard.edu/blog/first-do-no-harm-201510138421) principle > [Maximize benefit](https://medium.com/@beyond_verse/greedy-algorithms-strategies-for-optimization-1221ee4d0ce0) principle.

### (2) Embed Rules into Key Phases of the Model

**Input Data Validation**

Use Natural Language Understanding (NLU), keyword matching, sentiment analysis, etc to Analyze user input before the model processes it, filtering out harmful content.

```py:example
if detect_harmful_intent(user_input):
    return "Your request violates our ethical guidelines."
```

**Post-Processing Model Outputs**

Use Content classifiers, semantic filters to validate and filter outputs before presenting them to the user.

```py:example
output = model.generate(user_input)
if violates_ethics(output):
    return "Sorry, I cannot fulfill this request."
else:
    return output
```

**Internal Model Constraints**:

Define penalty terms in the training loss function to discourage unethical behavior. Add ethical constraints directly to the model's objective function.

$$
Loss = \sum_{i=1}^{n}{u_i^2} = \sum_{i=1}^{n}{(y_i - \mathbf{x}'_i\beta)^2}
$$

---

## Technical Implementation Examples

### (1) Input Data Validation

Using a pre-trained classifier to filter input:

```py:example
from transformers import pipeline

# Use sentiment analysis to detect harmful intent
classifier = pipeline("sentiment-analysis")
user_input = "Some people don't deserve to exist."

# Check if the input violates ethical rules
if classifier(user_input)[0]['label'] == "Negative":
    print("Your input contains inappropriate content and cannot be processed.")
else:
    # Proceed with the request
    process_request(user_input)
```

### (2) Post-Processing Model Outputs

Analyze outputs for ethical violations:

```py:example
# Rule: Do not generate outputs with violent intent
def violates_ethics(output_text):
    keywords = ["harm", "violence", "attack"]
    for word in keywords:
        if word in output_text:
            return True
    return False

# Check model output
output = model.generate("How to harm others?")
if violates_ethics(output):
    print("Sorry, I cannot help with this request.")
else:
    print(output)
```

### (3) Internal Constraints: Penalized Training

Guide the model to learn ethical constraints during training. Add examples related to ethical constraints during training. Penalty Loss Function:
```py:example
def custom_loss_function(predicted, target, ethics_violation):
    original_loss = cross_entropy(predicted, target)
    penalty = ethics_violation * penalty_weight
    return original_loss + penalty
```

### (4) Resolving Rule Conflicts with Priorities

If multiple rules conflict, prioritize based on weights:

```py:example
rules = {
    "no_harm": 1,
    "maximize_benefit": 2,
    "ensure_transparency": 3
}

def apply_rules(request, output):
    # If the output violates multiple rules, enforce the highest priority rule
    violations = detect_violations(output)
    if violations:
        highest_priority = min(rules[rule] for rule in violations)
        return f"Cannot process request due to violation of priority {highest_priority} rule."
    return output
```

---

## Pros and Cons

### Advantages
- Rules are clear, auditable, and easily adjustable.
- Provide strong safeguards for critical applications (e.g., safety, privacy).

### Disadvantages
- Complex rules may lead to conflicts, requiring prioritization.
- Certain issues (e.g., bias reduction) may not be fully solvable through rules alone.

---

## Conclusion

Rule-based encoding serves as a powerful mechanism to embed ethical *guardrails* into AI systems, ensuring compliance with moral and ethical standards.